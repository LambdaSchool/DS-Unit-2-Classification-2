{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Lambda School Data Science — Classification 2_ \n",
    "\n",
    "\n",
    "\n",
    "# Class Imbalance, ROC AUC\n",
    "\n",
    "### Objectives \n",
    "- Understand why accuracy is a misleading metric when classes are imbalanced\n",
    "- Use classification metric: ROC AUC\n",
    "- Visualize the ROC curve by plotting true positive rate vs false positive rate at varying thresholds\n",
    "- Use the class_weight parameter in scikit-learn\n",
    "\n",
    "### Libraries\n",
    "\n",
    "#### category_encoders\n",
    "- Local Anaconda: `conda install -c conda-forge category_encoders`\n",
    "- Google Colab: `pip install category_encoders`\n",
    "\n",
    "#### [mlxtend](http://rasbt.github.io/mlxtend/) (to plot decision regions)\n",
    "- Local Anaconda: `conda install -c conda-forge mlxtend`\n",
    "- Google Colab: Already installed\n",
    "\n",
    "#### [tqdm](https://tqdm.github.io/) (for progress bars)\n",
    "- Local Anaconda: `conda install -c conda-forge tqdm`\n",
    "- Google Colab: Already installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lending Club Review 🏦\n",
    "\n",
    "This sprint, your project is with Lending Club data, historical and current. Predict if peer-to-peer loans are charged off or fully paid. Decide which loans to invest in.\n",
    "\n",
    "#### Background\n",
    "\n",
    "[According to Wikipedia,](https://en.wikipedia.org/wiki/Lending_Club)\n",
    "\n",
    "> Lending Club is the world's largest peer-to-peer lending platform. Lending Club enables borrowers to create unsecured personal loans between \\\\$1,000 and \\\\$40,000. The standard loan period is three years. **Investors can search and browse the loan listings on Lending Club website and select loans that they want to invest in based on the information supplied about the borrower, amount of loan, loan grade, and loan purpose.** Investors make money from interest. Lending Club makes money by charging borrowers an origination fee and investors a service fee.\n",
    "\n",
    "Lending Club's article about [Benefits of diversification](https://www.lendingclub.com/investing/investor-education/benefits-of-diversification) explains,\n",
    "\n",
    "> **With the investment minimum of \\\\$1,000, you can get up to 40 Notes at \\\\$25 each.**\n",
    "\n",
    "You can read more good context in [Data-Driven Investment Strategies for Peer-to-Peer Lending: A Case Study for Teaching Data Science](https://www.liebertpub.com/doi/full/10.1089/big.2018.0092):\n",
    "\n",
    "> Current refers to a loan that is still being reimbursed in a timely manner. Late corresponds to a loan on which a payment is between 16 and 120 days overdue. If the payment is delayed by more than 121 days, the loan is considered to be in Default. If LendingClub has decided that the loan will not be paid off, then it is given the status of Charged-Off.\n",
    "\n",
    "> These dynamics imply that 5 months after the term of each loan has ended, every loan ends in one of two LendingClub states—fully paid or charged-off. We call these two statuses fully paid and defaulted, respectively, and we refer to a loan that has reached one of these statuses as expired. **One way to simplify the problem is to consider only loans that have expired at the time of analysis.**\n",
    "\n",
    "> A significant portion (13.5%) of loans ended in Default status; depending on how much of the loan was paid back, these loans\n",
    "might have resulted in a significant loss to investors who had invested in them. The remainder was Fully Paid—the borrower fully reimbursed the loan’s outstanding balance with interest, and the investor earned a positive return on his or her investment. Therefore, to avoid unsuccessful investments, **our goal is to estimate which loans are more likely to default and which will yield low returns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_location = '../data/lending-club-subset.csv'\n",
    "current_location = '../data/primaryMarketNotes_browseNotes_1-RETAIL.csv'\n",
    "\n",
    "# # For Google Colab, uncomment:\n",
    "# history_location = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Classification-2/master/data/lending-club-subset.csv'\n",
    "# current_location = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Classification-2/master/data/primaryMarketNotes_browseNotes_1-RETAIL.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.max_rows = 200\n",
    "\n",
    "# Stratified sample, 10% of expired Lending Club loans, grades A-D\n",
    "# Source: https://www.lendingclub.com/info/download-data.action\n",
    "history = pd.read_csv(history_location)\n",
    "history['issue_d'] = pd.to_datetime(history['issue_d'], infer_datetime_format=True)\n",
    "\n",
    "# Current loans available for manual investing, June 17, 2019\n",
    "# Source: https://www.lendingclub.com/browse/browse.action\n",
    "current = pd.read_csv(current_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percent of each loan repaid\n",
    "history['percent_paid'] = history['total_pymnt'] / history['funded_amnt']\n",
    "\n",
    "# See percent paid for charged off vs fully paid loans\n",
    "history.groupby('loan_status')['percent_paid'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin with baselines: expected value of random decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import percentileofscore\n",
    "import seaborn as sns\n",
    "from tqdm import tnrange\n",
    "\n",
    "def simulate(n=10000, grades=['A','B','C','D'], \n",
    "             start_date='2007-07-01', \n",
    "             end_date='2019-03-01'):\n",
    "    \"\"\"\n",
    "    What if you picked 40 random loans for $25 investments?\n",
    "    How much would you have been paid back?\n",
    "    \n",
    "    Repeat the simulation many times, and plot the distribution \n",
    "    of probable outcomes.\n",
    "    \n",
    "    This doesn't consider fees or \"time value of money.\"\n",
    "    \"\"\"\n",
    "    \n",
    "    condition = ((history['grade'].isin(grades)) & \n",
    "                 (history['issue_d'] >= start_date) &\n",
    "                 (history['issue_d'] <= end_date))\n",
    "    possible = history[condition]\n",
    "    \n",
    "    simulations = []\n",
    "    for _ in tnrange(n):\n",
    "        picks = possible.sample(40).copy()\n",
    "        picks['paid'] = 25 * picks['percent_paid']\n",
    "        paid = picks['paid'].sum()\n",
    "        simulations.append(paid)\n",
    "        \n",
    "    simulations = pd.Series(simulations)\n",
    "    sns.distplot(simulations)\n",
    "    plt.axvline(x=1000)\n",
    "    percent = percentileofscore(simulations, 1000)\n",
    "    plt.title(f'{percent}% of simulations did not profit. {start_date}-{end_date}, {grades}')\n",
    "\n",
    "simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate(grades=['A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate(grades=['D'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove features to avoid leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform earliest_cr_line to an integer:\n",
    "# How many days the earliest credit line was open, before the loan was issued.\n",
    "# For current loans available for manual investing, assume the loan will be issued today.\n",
    "\n",
    "history['earliest_cr_line'] = pd.to_datetime(history['earliest_cr_line'], infer_datetime_format=True)\n",
    "history['earliest_cr_line'] = history['issue_d'] - history['earliest_cr_line']\n",
    "history['earliest_cr_line'] = history['earliest_cr_line'].dt.days\n",
    "\n",
    "current['earliest_cr_line'] = pd.to_datetime(current['earliest_cr_line'], infer_datetime_format=True)\n",
    "current['earliest_cr_line'] = pd.Timestamp.today() - current['earliest_cr_line']\n",
    "current['earliest_cr_line'] = current['earliest_cr_line'].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Python sets to compare the historical columns & current columns\n",
    "\n",
    "common_columns = set(history.columns) & set(current.columns)\n",
    "just_history = set(history.columns) - set(current.columns)\n",
    "just_current = set(current.columns) - set(history.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on the historical data.\n",
    "# For features, use only the common columns shared by the historical & current data.\n",
    "# For the target, use `loan_status` ('Fully Paid' or 'Charged Off')\n",
    "\n",
    "features = list(common_columns)\n",
    "target = 'loan_status'\n",
    "X = history[features]\n",
    "y = history[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do train/validate/test 3-way split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=20000, stratify=y, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=20000, \n",
    "    stratify=y_trainval, random_state=42)\n",
    "\n",
    "print('X_train shape', X_train.shape)\n",
    "print('y_train shape', y_train.shape)\n",
    "print('X_val shape', X_val.shape)\n",
    "print('y_val shape', y_val.shape)\n",
    "print('X_test shape', X_test.shape)\n",
    "print('y_test shape', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand why accuracy is a misleading metric when classes are imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get accuracy score for majority class baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get confusion matrix for majority class baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    labels = unique_labels(y_true)\n",
    "    columns = [f'Predicted {label}' for label in labels]\n",
    "    index = [f'Actual {label}' for label in labels]\n",
    "    table = pd.DataFrame(confusion_matrix(y_true, y_pred), \n",
    "                         columns=columns, index=index)\n",
    "    return sns.heatmap(table, annot=True, fmt='d', cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get precision & recall for majority class baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ROC AUC score for majority class baseline\n",
    "[sklearn.metrics.roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_counts = X_train.isnull().sum().sort_values(ascending=False)\n",
    "null_counts.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_nulls = null_counts[:73].index\n",
    "print(list(many_nulls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrangle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def wrangle(X):\n",
    "    X = X.copy()\n",
    "\n",
    "    # Convert percentages from strings to floats\n",
    "    X['int_rate'] = X['int_rate'].str.strip('%').astype(float)\n",
    "    X['revol_util'] = X['revol_util'].str.strip('%').astype(float)\n",
    "        \n",
    "    # Create features for three employee titles: teacher, manager, owner\n",
    "    X['emp_title'] = X['emp_title'].str.lower()\n",
    "    X['emp_title_teacher'] = X['emp_title'].str.contains('teacher', na=False)\n",
    "    X['emp_title_manager'] = X['emp_title'].str.contains('manager', na=False)\n",
    "    X['emp_title_owner']   = X['emp_title'].str.contains('owner', na=False)\n",
    "\n",
    "    # Transform features with many nulls to binary flags\n",
    "    many_nulls = ['member_id', 'sec_app_mths_since_last_major_derog', 'sec_app_revol_util', \n",
    "                  'sec_app_open_act_il', 'sec_app_chargeoff_within_12_mths', 'sec_app_mort_acc', \n",
    "                  'sec_app_fico_range_high', 'revol_bal_joint', 'sec_app_collections_12_mths_ex_med', \n",
    "                  'sec_app_inq_last_6mths', 'sec_app_num_rev_accts', 'sec_app_open_acc', \n",
    "                  'sec_app_earliest_cr_line', 'sec_app_fico_range_low', 'annual_inc_joint', \n",
    "                  'dti_joint', 'desc', 'mths_since_last_record', 'mths_since_recent_bc_dlq', \n",
    "                  'mths_since_last_major_derog', 'mths_since_recent_revol_delinq', 'il_util', \n",
    "                  'mths_since_rcnt_il', 'all_util', 'open_il_12m', 'total_bal_il', 'open_il_24m', \n",
    "                  'inq_last_12m', 'open_rv_12m', 'max_bal_bc', 'open_act_il', 'open_rv_24m', 'inq_fi', \n",
    "                  'open_acc_6m', 'total_cu_tl', 'mths_since_last_delinq', 'mths_since_recent_inq', \n",
    "                  'num_tl_120dpd_2m', 'mo_sin_old_il_acct', 'emp_title', 'emp_length', 'pct_tl_nvr_dlq', \n",
    "                  'avg_cur_bal', 'mo_sin_rcnt_rev_tl_op', 'num_actv_bc_tl', 'num_il_tl', \n",
    "                  'mo_sin_rcnt_tl', 'total_rev_hi_lim', 'tot_cur_bal', 'num_bc_tl', 'num_tl_30dpd', \n",
    "                  'num_op_rev_tl', 'mo_sin_old_rev_tl_op', 'total_il_high_credit_limit', \n",
    "                  'num_rev_tl_bal_gt_0', 'num_accts_ever_120_pd', 'num_tl_90g_dpd_24m', \n",
    "                  'num_tl_op_past_12m', 'num_rev_accts', 'tot_hi_cred_lim', 'tot_coll_amt', \n",
    "                  'num_actv_rev_tl', 'bc_util', 'percent_bc_gt_75', 'bc_open_to_buy', \n",
    "                  'mths_since_recent_bc', 'num_bc_sats', 'num_sats', 'total_bc_limit', \n",
    "                  'acc_open_past_24mths', 'total_bal_ex_mort', 'mort_acc', 'title']\n",
    "    \n",
    "    for col in many_nulls:\n",
    "        X[col] = X[col].isnull()\n",
    "    \n",
    "    # For features with few nulls, do mean imputation\n",
    "    for col in X:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "            X[col] = X[col].fillna(X[col].mean())\n",
    "            \n",
    "    # Drop some columns\n",
    "    X = X.drop(columns='id')  # id is random\n",
    "    X = X.drop(columns='member_id')  # member_id is always null\n",
    "    X = X.drop(columns='title')  # Duplicative of purpose\n",
    "    X = X.drop(columns='grade')  # Duplicative of sub_grade\n",
    "    X = X.drop(columns='zip_code') # High cardinality\n",
    "\n",
    "    # Transform sub_grade from \"A1\" - \"G5\" to 1.1 - 7.5\n",
    "    def wrangle_sub_grade(x):\n",
    "        first_digit = ord(x[0]) - 64\n",
    "        second_digit = int(x[1])\n",
    "        return first_digit + second_digit/10\n",
    "    \n",
    "    X['sub_grade'] = X['sub_grade'].apply(wrangle_sub_grade)\n",
    "    \n",
    "    # Return the wrangled dataframe\n",
    "    return X\n",
    "\n",
    "\n",
    "X_train = wrangle(X_train)\n",
    "X_val   = wrangle(X_val)\n",
    "X_test  = wrangle(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import category_encoders as ce\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get accuracy score for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get confusion matrix for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get precision & recall for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ROC AUC score for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand ROC AUC (Receiver Operating Characteristic, Area Under the Curve)\n",
    "\n",
    "#### Scikit-Learn docs\n",
    "- [User Guide: Receiver operating characteristic (ROC)](https://scikit-learn.org/stable/modules/model_evaluation.html#receiver-operating-characteristic-roc)\n",
    "- [sklearn.metrics.roc_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html)\n",
    "- [sklearn.metrics.roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)\n",
    "\n",
    "#### More links\n",
    "- [ROC curves and Area Under the Curve explained](https://www.dataschool.io/roc-curves-and-auc-explained/)\n",
    "- [The philosophical argument for using ROC curves](https://lukeoakdenrayner.wordpress.com/2018/01/07/the-philosophical-argument-for-using-roc-curves/)\n",
    "\n",
    "[Wikipedia explains,](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) \"A receiver operating characteristic curve, or ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings.\"\n",
    "\n",
    "ROC AUC is the area under the ROC curve. [It can be interpreted](https://stats.stackexchange.com/questions/132777/what-does-auc-stand-for-and-what-is-it) as \"the expectation that a uniformly drawn random positive is ranked before a uniformly drawn random negative.\" \n",
    "\n",
    "ROC AUC measures how well a classifier ranks predicted probabilities. It ranges from 0 to 1. A naive majority class baseline will have an ROC AUC score of 0.5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the ROC curve by plotting true positive rate vs false positive rate at varying thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, fixed\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "def set_threshold(y_true, y_pred_proba, threshold=0.5):\n",
    "    \"\"\"\n",
    "    For binary classification problems. \n",
    "    y_pred_proba : predicted probability of class 1\n",
    "    \"\"\"\n",
    "    \n",
    "    # Apply threshold to predicted probabilities\n",
    "    # to get discrete predictions\n",
    "    class_0, class_1 = unique_labels(y_true)\n",
    "    y_pred = np.full_like(y_true, fill_value=class_0)\n",
    "    y_pred[y_pred_proba > threshold] = class_1\n",
    "    \n",
    "    # Plot distribution of predicted probabilities\n",
    "    ax = sns.distplot(y_pred_proba)\n",
    "    ax.axvline(threshold, color='red')\n",
    "    plt.title('Distribution of predicted probabilities')\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate true positive rate and false positive rate\n",
    "    true_positives = (y_pred==y_true) & (y_pred==class_1)\n",
    "    false_positives = (y_pred!=y_true) & (y_pred==class_1)\n",
    "    actual_positives = (y_true==class_1)\n",
    "    actual_negatives = (y_true==class_0)\n",
    "    true_positive_rate = true_positives.sum() / actual_positives.sum()\n",
    "    false_positive_rate = false_positives.sum() / actual_negatives.sum()\n",
    "    print('False Positive Rate', false_positive_rate)\n",
    "    print('True Positive Rate', true_positive_rate)\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_true==class_1, y_pred_proba)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.title('ROC curve')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    \n",
    "    # Plot point on ROC curve for the current threshold\n",
    "    plt.scatter(false_positive_rate, true_positive_rate)\n",
    "    plt.show()\n",
    "    \n",
    "    # Show ROC AUC score\n",
    "    print('Area under the Receiver Operating Characteristic curve:', \n",
    "          roc_auc_score(y_true, y_pred_proba))\n",
    "    \n",
    "    # Show confusion matrix & classification report\n",
    "    plot_confusion_matrix(y_true, y_pred)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "interact(set_threshold, \n",
    "         y_true=fixed(y_val), \n",
    "         y_pred_proba=fixed(y_pred_proba), \n",
    "         threshold=(0,1,0.05));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the class_weight parameter in scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a fun demo you can explore! The next code cells do five things:\n",
    "\n",
    "#### 1. Generate data\n",
    "\n",
    "We use scikit-learn's [make_classification](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) function to generate fake data for a binary classification problem, based on several parameters, including:\n",
    "- Number of samples\n",
    "- Weights, meaning \"the proportions of samples assigned to each class.\"\n",
    "- Class separation: \"Larger values spread out the clusters/classes and make the classification task easier.\"\n",
    "\n",
    "(We are generating fake data so it is easy to visualize.)\n",
    "\n",
    "#### 2. Split data\n",
    "\n",
    "We split the data three ways, into train, validation, and test sets. (For this toy example, it's not really necessary to do a three-way split. A two-way split, or even no split, would be ok. But I'm trying to demonstrate good habits, even in toy examples, to avoid confusion.)\n",
    "\n",
    "#### 3. Fit model\n",
    "\n",
    "We use scikit-learn to fit a [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) on the training data.\n",
    "\n",
    "We use this model parameter:\n",
    "\n",
    "> **class_weight : _dict or ‘balanced’, default: None_**\n",
    "\n",
    "> Weights associated with classes in the form `{class_label: weight}`. If not given, all classes are supposed to have weight one.\n",
    "\n",
    "> The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as `n_samples / (n_classes * np.bincount(y))`.\n",
    "\n",
    "\n",
    "#### 4. Evaluate model\n",
    "\n",
    "We use our Logistic Regression model, which was fit on the training data, to generate predictions for the validation data.\n",
    "\n",
    "Then we print [scikit-learn's Classification Report](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-report), with many metrics, and also the accuracy score. We are comparing the correct labels to the Logistic Regression's predicted labels, for the validation set. \n",
    "\n",
    "#### 5. Visualize decision function\n",
    "\n",
    "Based on these examples\n",
    "- https://imbalanced-learn.readthedocs.io/en/stable/auto_examples/combine/plot_comparison_combine.html\n",
    "- http://rasbt.github.io/mlxtend/user_guide/plotting/plot_decision_regions/#example-1-decision-regions-in-2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_validation_test_split(\n",
    "    X, y, train_size=0.8, val_size=0.1, test_size=0.1, \n",
    "    random_state=None, shuffle=True):\n",
    "        \n",
    "    assert train_size + val_size + test_size == 1\n",
    "    \n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, shuffle=shuffle)\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=val_size/(train_size+val_size), \n",
    "        random_state=random_state, shuffle=shuffle)\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "\n",
    "#1. Generate data\n",
    "\n",
    "# Try re-running the cell with different values for these parameters\n",
    "n_samples = 1000\n",
    "weights = (0.95, 0.05)\n",
    "class_sep = 0.8\n",
    "\n",
    "X, y = make_classification(n_samples=n_samples, n_features=2, n_informative=2, \n",
    "                           n_redundant=0, n_repeated=0, n_classes=2, \n",
    "                           n_clusters_per_class=1, weights=weights, \n",
    "                           class_sep=class_sep, random_state=0)\n",
    "\n",
    "\n",
    "# 2. Split data\n",
    "\n",
    "# Uses our custom train_validation_test_split function\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = train_validation_test_split(\n",
    "    X, y, train_size=0.8, val_size=0.1, test_size=0.1, random_state=1)\n",
    "\n",
    "\n",
    "# 3. Fit model\n",
    "\n",
    "# Try re-running the cell with different values for this parameter\n",
    "class_weight = None\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', class_weight=class_weight)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# 4. Evaluate model\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))\n",
    "plot_confusion_matrix(y_val, y_pred)\n",
    "\n",
    "# 5. Visualize decision regions\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_decision_regions(X_val, y_val, model, legend=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try re-running the cell above with different values for these four parameters:\n",
    "- `n_samples`\n",
    "- `weights`\n",
    "- `class_sep`\n",
    "- `class_balance`\n",
    "\n",
    "For example, with a 50% / 50% class distribution:\n",
    "```\n",
    "n_samples = 1000\n",
    "weights = (0.50, 0.50)\n",
    "class_sep = 0.8\n",
    "class_balance = None\n",
    "```\n",
    "\n",
    "With a 95% / 5% class distribution:\n",
    "```\n",
    "n_samples = 1000\n",
    "weights = (0.95, 0.05)\n",
    "class_sep = 0.8\n",
    "class_balance = None\n",
    "```\n",
    "\n",
    "With the same 95% / 5% class distribution, but changing the Logistic Regression's `class_balance` parameter to `'balanced'` (instead of its default `None`)\n",
    "```\n",
    "n_samples = 1000\n",
    "weights = (0.95, 0.05)\n",
    "class_sep = 0.8\n",
    "class_balance = 'balanced'\n",
    "```\n",
    "\n",
    "With the same 95% / 5% class distribution, but with different values for `class_balance`:\n",
    "- `{0: 1, 1: 1}` _(equivalent to `None`)_\n",
    "- `{0: 1, 1: 2}`\n",
    "- `{0: 1, 1: 10}` _(roughly equivalent to `'balanced'` for this dataset)_\n",
    "- `{0: 1, 1: 100}`\n",
    "- `{0: 1, 1: 10000}`\n",
    "\n",
    "How do the evaluation metrics and decision region plots change?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What you can do about imbalanced classes\n",
    "\n",
    "[Learning from Imbalanced Classes](https://www.svds.com/tbt-learning-imbalanced-classes/) gives \"a rough outline of useful approaches\" : \n",
    "\n",
    "- Do nothing. Sometimes you get lucky and nothing needs to be done. You can train on the so-called natural (or stratified) distribution and sometimes it works without need for modification.\n",
    "- Balance the training set in some way:\n",
    "  - Oversample the minority class.\n",
    "  - Undersample the majority class.\n",
    "  - Synthesize new minority classes.\n",
    "- Throw away minority examples and switch to an anomaly detection framework.\n",
    "- At the algorithm level, or after it:\n",
    "  - Adjust the class weight (misclassification costs).\n",
    "  - Adjust the decision threshold.\n",
    "  - Modify an existing algorithm to be more sensitive to rare classes.\n",
    "- Construct an entirely new algorithm to perform well on imbalanced data.\n",
    "\n",
    "#### We demonstrated two of these options: \n",
    "\n",
    "- \"Adjust the class weight (misclassification costs)\" — many scikit-learn classifiers have a `class_balance` parameter\n",
    "- \"Adjust the decision threshold\" — you can lean more about this in a great blog post, [Visualizing Machine Learning Thresholds to Make Better Business Decisions](https://blog.insightdatascience.com/visualizing-machine-learning-thresholds-to-make-better-business-decisions-4ab07f823415).\n",
    "\n",
    "#### Another option to be aware of:\n",
    "- The [imbalance-learn](https://github.com/scikit-learn-contrib/imbalanced-learn) library can be used to \"oversample the minority class, undersample the majority class, or synthesize new minority classes.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGNMENT\n",
    "\n",
    "- Wrangle and model the Lending Club data. Improve your ROC AUC score! Discuss on Slack.\n",
    "- Explore the class_weight demo.\n",
    "- Read the pre-reads (if you haven't already)\n",
    "  - [ROC curves and Area Under the Curve explained](https://www.dataschool.io/roc-curves-and-auc-explained/)\n",
    "  - [Learning from Imbalanced Classes](https://www.svds.com/tbt-learning-imbalanced-classes/)\n",
    "\n",
    "### Stretch Goals\n",
    "\n",
    "Explore these links!\n",
    "\n",
    "- [imbalance-learn](https://github.com/scikit-learn-contrib/imbalanced-learn)\n",
    "- [Machine Learning Meets Economics](http://blog.mldb.ai/blog/posts/2016/01/ml-meets-economics/)\n",
    "- [The philosophical argument for using ROC curves](https://lukeoakdenrayner.wordpress.com/2018/01/07/the-philosophical-argument-for-using-roc-curves/)\n",
    "- [Visualizing Machine Learning Thresholds to Make Better Business Decisions](https://blog.insightdatascience.com/visualizing-machine-learning-thresholds-to-make-better-business-decisions-4ab07f823415)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
