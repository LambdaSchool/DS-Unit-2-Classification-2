{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Lambda School Data Science ‚Äî Classification 2_ \n",
    "\n",
    "# Making & explaining decisions\n",
    "\n",
    "### Objectives\n",
    "- Make decisions with probability calibration and expected value calculations\n",
    "- Explain decisions with shapley value plots\n",
    "\n",
    "### Libraries\n",
    "\n",
    "#### category_encoders\n",
    "- Local Anaconda: `conda install -c conda-forge category_encoders`\n",
    "- Google Colab: `pip install category_encoders`\n",
    "\n",
    "#### [shap](https://github.com/slundberg/shap) (for shapley value plots)\n",
    "- Local Anaconda: `conda install -c conda-forge shap` ***(I'm getting import errors locally)***\n",
    "- Google Colab: `pip install shap`\n",
    "\n",
    "#### [tqdm](https://tqdm.github.io/) (for progress bars)\n",
    "- Local Anaconda: `conda install -c conda-forge tqdm`\n",
    "- Google Colab: Already installed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lending Club Review üè¶\n",
    "\n",
    "This sprint, your project is with Lending Club data, historical and current. Predict if peer-to-peer loans are charged off or fully paid. Decide which loans to invest in.\n",
    "\n",
    "#### Changes from the previous lesson\n",
    "- Engineer more date features\n",
    "- After splitting the data, but before wrangling it, save the actual results (percent of each loan repaid) for each set, to compare later with the predicted results\n",
    "- Engineer and select different features in the wrangle function\n",
    "- Use xgboost instead of random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_location = '../data/lending-club-subset.csv'\n",
    "current_location = '../data/primaryMarketNotes_browseNotes_1-RETAIL.csv'\n",
    "\n",
    "# # For Google Colab, uncomment:\n",
    "# history_location = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Classification-2/master/data/lending-club-subset.csv'\n",
    "# current_location = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Classification-2/master/data/primaryMarketNotes_browseNotes_1-RETAIL.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.max_rows = 200\n",
    "\n",
    "# Stratified sample, 10% of expired Lending Club loans, grades A-D\n",
    "# Source: https://www.lendingclub.com/info/download-data.action\n",
    "history = pd.read_csv(history_location)\n",
    "history['issue_d'] = pd.to_datetime(history['issue_d'], infer_datetime_format=True)\n",
    "\n",
    "# Current loans available for manual investing, June 17, 2019\n",
    "# Source: https://www.lendingclub.com/browse/browse.action\n",
    "current = pd.read_csv(current_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform earliest_cr_line to an integer:\n",
    "# How many days the earliest credit line was open, before the loan was issued.\n",
    "# For current loans available for manual investing, assume the loan will be issued today.\n",
    "history['earliest_cr_line'] = pd.to_datetime(history['earliest_cr_line'], infer_datetime_format=True)\n",
    "history['earliest_cr_line'] = history['issue_d'] - history['earliest_cr_line']\n",
    "history['earliest_cr_line'] = history['earliest_cr_line'].dt.days\n",
    "\n",
    "current['earliest_cr_line'] = pd.to_datetime(current['earliest_cr_line'], infer_datetime_format=True)\n",
    "current['earliest_cr_line'] = pd.Timestamp.today() - current['earliest_cr_line']\n",
    "current['earliest_cr_line'] = current['earliest_cr_line'].dt.days\n",
    "\n",
    "# Transform earliest_cr_line for the secondary applicant\n",
    "history['sec_app_earliest_cr_line'] = pd.to_datetime(history['sec_app_earliest_cr_line'], infer_datetime_format=True, errors='coerce')\n",
    "history['sec_app_earliest_cr_line'] = history['issue_d'] - history['sec_app_earliest_cr_line']\n",
    "history['sec_app_earliest_cr_line'] = history['sec_app_earliest_cr_line'].dt.days\n",
    "\n",
    "current['sec_app_earliest_cr_line'] = pd.to_datetime(current['sec_app_earliest_cr_line'], infer_datetime_format=True, errors='coerce')\n",
    "current['sec_app_earliest_cr_line'] = pd.Timestamp.today() - current['sec_app_earliest_cr_line']\n",
    "current['sec_app_earliest_cr_line'] = current['sec_app_earliest_cr_line'].dt.days\n",
    "\n",
    "# Engineer features for issue date year & month\n",
    "history['issue_d_year'] = history['issue_d'].dt.year\n",
    "history['issue_d_month'] = history['issue_d'].dt.month\n",
    "\n",
    "current['issue_d_year'] = pd.Timestamp.today().year\n",
    "current['issue_d_month'] = pd.Timestamp.today().month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percent of each loan repaid\n",
    "history['percent_paid'] = history['total_pymnt'] / history['funded_amnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on the historical data.\n",
    "# For the target, use `loan_status` ('Fully Paid' or 'Charged Off')\n",
    "target = 'loan_status'\n",
    "X = history.drop(columns=target)\n",
    "y = history[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do train/validate/test 3-way split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=20000, stratify=y, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=20000, \n",
    "    stratify=y_trainval, random_state=42)\n",
    "\n",
    "print('X_train shape', X_train.shape)\n",
    "print('y_train shape', y_train.shape)\n",
    "print('X_val shape', X_val.shape)\n",
    "print('y_val shape', y_val.shape)\n",
    "print('X_test shape', X_test.shape)\n",
    "print('y_test shape', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the actual results, to compare later with predicted results\n",
    "cols = ['id', 'issue_d', 'grade', 'percent_paid', 'term', 'int_rate']\n",
    "result_train = X_train[cols].copy()\n",
    "result_val = X_val[cols].copy()\n",
    "result_test = X_test[cols].copy()\n",
    "\n",
    "result_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Python sets to compare the historical columns & current columns\n",
    "common_columns = set(history.columns) & set(current.columns)\n",
    "just_history = set(history.columns) - set(current.columns)\n",
    "just_current = set(current.columns) - set(history.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For features, use only the common columns shared by the historical & current data.\n",
    "features = list(common_columns)\n",
    "X_train = X_train[features]\n",
    "X_val = X_val[features]\n",
    "X_test = X_test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(X):\n",
    "    X = X.copy()\n",
    "\n",
    "    # Engineer new feature for every feature: is the feature null?\n",
    "    for col in X:\n",
    "        X[col+'_NULL'] = X[col].isnull()\n",
    "    \n",
    "    # Convert percentages from strings to floats\n",
    "    X['int_rate'] = X['int_rate'].str.strip('%').astype(float)\n",
    "    X['revol_util'] = X['revol_util'].str.strip('%').astype(float)\n",
    "    \n",
    "    # Convert employment length from string to float\n",
    "    X['emp_length'] = X['emp_length'].str.replace(r'\\D','').astype(float)\n",
    "        \n",
    "    # Create features for three employee titles: teacher, manager, owner\n",
    "    X['emp_title'] = X['emp_title'].str.lower()\n",
    "    X['emp_title_teacher'] = X['emp_title'].str.contains('teacher', na=False)\n",
    "    X['emp_title_manager'] = X['emp_title'].str.contains('manager', na=False)\n",
    "    X['emp_title_owner']   = X['emp_title'].str.contains('owner', na=False)\n",
    "\n",
    "    # Get length of free text fields\n",
    "    X['title'] = X['title'].str.len()\n",
    "    X['desc'] = X['desc'].str.len()\n",
    "    X['emp_title'] = X['emp_title'].str.len()\n",
    "    \n",
    "    # Convert sub_grade from string \"A1\"-\"D5\" to integer 1-20\n",
    "    sub_grade_ranks = {'A1': 1, 'A2': 2, 'A3': 3, 'A4': 4, 'A5': 5, 'B1': 6, 'B2': 7, \n",
    "                       'B3': 8, 'B4': 9, 'B5': 10, 'C1': 11, 'C2': 12, 'C3': 13, 'C4': 14, \n",
    "                       'C5': 15, 'D1': 16, 'D2': 17, 'D3': 18, 'D4': 19, 'D5': 20}\n",
    "    X['sub_grade'] = X['sub_grade'].map(sub_grade_ranks)\n",
    "    \n",
    "    # Drop some columns\n",
    "    X = X.drop(columns='id')        # Always unique\n",
    "    X = X.drop(columns='url')       # Always unique\n",
    "    X = X.drop(columns='member_id') # Always null\n",
    "    X = X.drop(columns='grade')     # Duplicative of sub_grade\n",
    "    X = X.drop(columns='zip_code')  # High cardinality\n",
    "    \n",
    "    # Only use these features which had nonzero permutation importances in earlier models    \n",
    "    features = ['acc_open_past_24mths', 'addr_state', 'all_util', 'annual_inc', \n",
    "                'annual_inc_joint', 'avg_cur_bal', 'bc_open_to_buy', 'bc_util', \n",
    "                'collections_12_mths_ex_med', 'delinq_amnt', 'desc_NULL', 'dti', \n",
    "                'dti_joint', 'earliest_cr_line', 'emp_length', 'emp_length_NULL', \n",
    "                'emp_title', 'emp_title_NULL', 'emp_title_owner', 'fico_range_high', \n",
    "                'funded_amnt', 'home_ownership', 'inq_last_12m', 'inq_last_6mths', \n",
    "                'installment', 'int_rate', 'issue_d_month', 'issue_d_year', 'loan_amnt', \n",
    "                'max_bal_bc', 'mo_sin_old_il_acct', 'mo_sin_old_rev_tl_op', \n",
    "                'mo_sin_rcnt_rev_tl_op', 'mort_acc', 'mths_since_last_major_derog_NULL', \n",
    "                'mths_since_last_record', 'mths_since_recent_bc', 'mths_since_recent_inq', \n",
    "                'num_actv_bc_tl', 'num_actv_rev_tl', 'num_op_rev_tl', 'num_rev_tl_bal_gt_0', \n",
    "                'num_tl_120dpd_2m_NULL', 'open_rv_12m_NULL', 'open_rv_24m', \n",
    "                'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'pub_rec_bankruptcies', 'purpose', \n",
    "                'revol_bal', 'revol_bal_joint', 'sec_app_earliest_cr_line', \n",
    "                'sec_app_fico_range_high', 'sec_app_open_acc', 'sec_app_open_act_il', \n",
    "                'sub_grade', 'term', 'title', 'title_NULL', 'tot_coll_amt', \n",
    "                'tot_hi_cred_lim', 'total_acc', 'total_bal_il', 'total_bc_limit', \n",
    "                'total_cu_tl', 'total_rev_hi_lim']    \n",
    "    X = X[features]\n",
    "    \n",
    "    # Return the wrangled dataframe\n",
    "    return X\n",
    "\n",
    "\n",
    "X_train = wrangle(X_train)\n",
    "X_val   = wrangle(X_val)\n",
    "X_test  = wrangle(X_test)\n",
    "\n",
    "print('X_train shape', X_train.shape)\n",
    "print('X_val shape', X_val.shape)\n",
    "print('X_test shape', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "processor = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    SimpleImputer(strategy='median')\n",
    ")\n",
    "\n",
    "X_train_processed = processor.fit_transform(X_train)\n",
    "X_val_processed = processor.transform(X_val)\n",
    "\n",
    "eval_set = [(X_train_processed, y_train), \n",
    "            (X_val_processed, y_val)]\n",
    "\n",
    "model = XGBClassifier(n_estimators=1000, n_jobs=-1)\n",
    "model.fit(X_train_processed, y_train, eval_set=eval_set, eval_metric='auc', \n",
    "          early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make decisions with probability calibration and expected value calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit-Learn User Guide, [Probability calibration](https://scikit-learn.org/stable/modules/calibration.html)\n",
    "\n",
    "> When performing classification you often want not only to predict the class label, but also obtain a probability of the respective label. \n",
    "\n",
    "> Well calibrated classifiers are probabilistic classifiers for which the output of the predict_proba method can be directly interpreted as a confidence level. For instance, a well calibrated (binary) classifier should classify the samples such that among the samples to which it gave a predict_proba value close to 0.8, approximately 80% actually belong to the positive class. The following plot compares how well the probabilistic predictions of different classifiers are calibrated:\n",
    "\n",
    "<img src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_compare_calibration_0011.png\" width=\"500\">\n",
    "\n",
    "> LogisticRegression returns well calibrated predictions by default as it directly optimizes log-loss. In contrast, the other methods return biased probabilities; with different biases per method ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jason Brownlee, [How and When to Use a Calibrated Classification Model with scikit-learn](https://machinelearningmastery.com/calibrated-classification-model-in-scikit-learn/)\n",
    "\n",
    "> **You can diagnose the calibration of a classifier by creating a reliability diagram** of the actual probabilities versus the predicted probabilities on a test set.\n",
    "\n",
    "> In scikit-learn, this is called a calibration curve. This can be implemented by first calculating the [`calibration_curve()` function](https://scikit-learn.org/stable/modules/generated/sklearn.calibration.calibration_curve.html). This function takes the true class values for a dataset and the predicted probabilities for the main class (class=1). The function returns the true probabilities for each bin and the predicted probabilities for each bin. The number of bins can be specified via the `n_bins` argument and default to 5.\n",
    "\n",
    "We can check our calibration curves and see that the probabilities are already reasonably well calibrated.\n",
    "\n",
    "[XGBClassifier](https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBClassifier) has a default parameter, `objective='binary:logistic'`. Like Logistic Regression, it returns well calibrated predictions by default. \n",
    "\n",
    "(However, if we'd used RandomForestClassifier, we'd likely need to calibrate its predictions using scikit-learn's CalibratedClassifierCV class.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve\n",
    "y_pred_proba = model.predict_proba(X_val_processed)[:, 1]\n",
    "prob_true, prob_pred = calibration_curve(y_val, y_pred_proba, n_bins=5)\n",
    "plt.plot((0,1), (0,1), linestyle='--', color='grey')\n",
    "plt.plot(prob_pred, prob_true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_true, prob_pred = calibration_curve(y_val, y_pred_proba, n_bins=10)\n",
    "plt.plot((0,1), (0,1), linestyle='--', color='grey')\n",
    "plt.plot(prob_pred, prob_true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_true, prob_pred = calibration_curve(y_val, y_pred_proba, n_bins=20)\n",
    "plt.plot((0,1), (0,1), linestyle='--', color='grey')\n",
    "plt.plot(prob_pred, prob_true);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected value calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(result_df, y_true, y_pred_proba):\n",
    "    result_df = result_df.copy()\n",
    "    result_df['loan_status'] = y_true\n",
    "    result_df['pred_proba'] = y_pred_proba\n",
    "    result_df['int_rate'] = result_df['int_rate'].str.strip('%').astype(float)\n",
    "    result_df['term'] = result_df['term'].str.replace(r'\\D','').astype(int)\n",
    "    result_df['max_interest'] = result_df['int_rate'] * result_df['term'] / 12\n",
    "    result_df['best_case'] = 25 + result_df['max_interest']/100 * 25\n",
    "    result_df['worst_case'] = -25\n",
    "    result_df['expected_value'] = (result_df['pred_proba'] * result_df['best_case'] \n",
    "                                   + (1-result_df['pred_proba']) * result_df['worst_case'])\n",
    "    return result_df\n",
    "\n",
    "result_val = get_results(result_val, y_val, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_val.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import display, Markdown\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import percentileofscore\n",
    "import seaborn as sns\n",
    "from tqdm import tnrange\n",
    "\n",
    "def simulate(df, n_picks=40, n_sims=10000, \n",
    "             grades=['A','B','C','D'], \n",
    "             start_date='2007-07-01', \n",
    "             end_date='2019-03-01', \n",
    "             min_expected_value=-25):\n",
    "    \"\"\"\n",
    "    What if you picked random loans for $25 investments?\n",
    "    How much would you have been paid back?\n",
    "    \n",
    "    Repeat the simulation many times, and plot the distribution \n",
    "    of probable outcomes.\n",
    "    \n",
    "    This doesn't consider fees or \"time value of money.\"\n",
    "    \"\"\"\n",
    "    \n",
    "    condition = ((df['grade'].isin(grades)) & \n",
    "                 (df['issue_d'] >= start_date) &\n",
    "                 (df['issue_d'] <= end_date) & \n",
    "                 (df['expected_value'] >= min_expected_value))\n",
    "    possible = df[condition]\n",
    "    \n",
    "    simulations = []\n",
    "    for _ in tnrange(n_sims):\n",
    "        picks = possible.sample(n_picks).copy()\n",
    "        picks['paid'] = 25 * picks['percent_paid']\n",
    "        paid = picks['paid'].sum()\n",
    "        simulations.append(paid)\n",
    "        \n",
    "    simulations = pd.Series(simulations)\n",
    "    sns.distplot(simulations)\n",
    "    plt.axvline(x=1000)\n",
    "    percent = percentileofscore(simulations, 1000)\n",
    "    display(Markdown(f'#### {n_picks} loans picked from {len(possible)} possible loans'))\n",
    "    display(Markdown(f'- Dates: {start_date}-{end_date}\\n' + \n",
    "                     f'- Grades: {grades}\\n' +\n",
    "                     f'- Expected Value >= {min_expected_value}'))\n",
    "    display(Markdown(f'#### Range of results from {n_sims} simulations'))\n",
    "    print(simulations.describe().to_string())\n",
    "    plt.title(f'{percent}% of simulations did not profit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we picked loans randomly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate(result_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we picked grade 'A' loans only?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate(result_val, grades=['A'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we picked loans using the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "min_expected_value = np.percentile(result_val['expected_value'], 80)\n",
    "simulate(result_val, min_expected_value=min_expected_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Time!\n",
    "\n",
    "https://twitter.com/Zach_Angell/status/1107982917463085056"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "X_test_processed = processor.transform(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test_processed)[:, 1]\n",
    "print('Test ROC AUC:', roc_auc_score(y_test, y_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = get_results(result_test, y_test, y_pred_proba)\n",
    "min_expected_value = np.percentile(result_test['expected_value'], 80)\n",
    "simulate(result_test, min_expected_value=min_expected_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain decisions with shapley value plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We're learning about 3 types of model explanations this unit:\n",
    "\n",
    "#### Global explanation:¬†all features in relation to each other\n",
    "What features have the most impact on my model's predictions?\n",
    "\n",
    "- Feature Importances: _Default, fastest, good for first estimates_\n",
    "- Drop-Column Importances: _The best in theory, but much too slow in practice_\n",
    "- Permutaton Importances: _A good compromise!_\n",
    "\n",
    "#### Global explanation:¬†individual feature(s) in relation to target\n",
    "What does my model predict if I vary some feature(s) and hold the other features constant?\n",
    "\n",
    "- Partial Dependence plots\n",
    "\n",
    "#### Individual prediction explanation\n",
    "Why does my model make this prediction for this individual observation? \n",
    "\n",
    "- Shapley Values\n",
    "\n",
    "_Note that the coefficients from a linear model give you all three types of explanations!_\n",
    "\n",
    "#### [Dan Becker explains Shapley Values:](https://www.kaggle.com/dansbecker/shap-values)\n",
    "\n",
    ">You've seen (and used) techniques to extract general insights from a machine learning model. But what if you want to break down how the model works for an individual prediction?\n",
    "\n",
    ">SHAP Values (an acronym from SHapley Additive exPlanations) break down a prediction to show the impact of each feature. \n",
    "\n",
    ">There is some complexity to the technique ... We won't go into that detail here, since it isn't critical for using the technique. [This blog post](https://towardsdatascience.com/one-feature-attribution-method-to-supposedly-rule-them-all-shapley-values-f3e04534983d) has a longer theoretical explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = result_test.copy()\n",
    "condition = (df['expected_value'] >= min_expected_value)\n",
    "possible = df[condition]\n",
    "picks = possible.sample(40, random_state=42).copy()\n",
    "picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_prediction = X_test[X_test.index==110718]\n",
    "data_for_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(data_for_prediction)\n",
    "shap.force_plot(explainer.expected_value, shap_values, data_for_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
